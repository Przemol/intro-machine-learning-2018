# Solutions ch. 8 - Artificial neural networks {#solutions-ann}

Solutions to exercises of chapter \@ref(ann).

## Exercise 1


```r
library("neuralnet")
 
#To create a neural network to perform square root

#Generate 50 random numbers uniformly distributed between 0 and 100
#And store them as a dataframe
traininginput <-  as.data.frame(runif(50, min=0, max=100))
trainingoutput <- sqrt(traininginput)
 
#Column bind the data into one variable
trainingdata <- cbind(traininginput,trainingoutput)
colnames(trainingdata) <- c("Input","Output")
 
#Train the neural network
#Will have 10 hidden layers
#Threshold is a numeric value specifying the threshold for the partial
#derivatives of the error function as stopping criteria.
net.sqrt <- neuralnet(Output~Input,trainingdata, hidden=10, threshold=0.01)
print(net.sqrt)
```

```
## $call
## neuralnet(formula = Output ~ Input, data = trainingdata, hidden = 10, 
##     threshold = 0.01)
## 
## $response
##          Output
## 1  5.6586565701
## 2  6.9072033934
## 3  1.4408099271
## 4  4.8050458632
## 5  4.1701072511
## 6  7.5689879018
## 7  8.5846254231
## 8  8.4579936175
## 9  4.7880397983
## 10 3.1345180313
## 11 7.6643980303
## 12 6.1617819432
## 13 8.0824655586
## 14 8.4449278389
## 15 6.5871164448
## 16 5.3215323149
## 17 6.8678056567
## 18 9.9977557078
## 19 2.7471997774
## 20 4.5458076864
## 21 8.0657670738
## 22 9.4188363920
## 23 9.8985316248
## 24 3.6912428981
## 25 6.8797764218
## 26 8.1766377440
## 27 2.1693127886
## 28 9.8700721091
## 29 4.3940544029
## 30 0.6986501642
## 31 5.4341274550
## 32 0.8914726395
## 33 8.9839051567
## 34 2.8608393007
## 35 6.0307735900
## 36 5.8332588175
## 37 8.2888276296
## 38 5.4020650921
## 39 9.6759479570
## 40 4.8565360482
## 41 6.9358358939
## 42 8.3114562871
## 43 7.1686029008
## 44 4.4649461258
## 45 5.3445363212
## 46 9.8929017888
## 47 5.0309394635
## 48 8.4264639060
## 49 8.7207848651
## 50 7.2042774109
## 
## $covariate
##               [,1]
##  [1,] 32.020394178
##  [2,] 47.709458717
##  [3,]  2.075933246
##  [4,] 23.088465747
##  [5,] 17.389794486
##  [6,] 57.289577858
##  [7,] 73.695793655
##  [8,] 71.537656034
##  [9,] 22.925325111
## [10,]  9.825203288
## [11,] 58.742997167
## [12,] 37.967556715
## [13,] 65.326249506
## [14,] 71.316806204
## [15,] 43.390103057
## [16,] 28.318706178
## [17,] 47.166754538
## [18,] 99.955119193
## [19,]  7.547106617
## [20,] 20.664367522
## [21,] 65.056598489
## [22,] 88.714478980
## [23,] 97.980928328
## [24,] 13.625274133
## [25,] 47.331323614
## [26,] 66.857404797
## [27,]  4.705917975
## [28,] 97.418323439
## [29,] 19.307714095
## [30,]  0.488112052
## [31,] 29.529741197
## [32,]  0.794723467
## [33,] 80.710551864
## [34,]  8.184401505
## [35,] 36.370230094
## [36,] 34.026908432
## [37,] 68.704663473
## [38,] 29.182307259
## [39,] 93.623968866
## [40,] 23.585942388
## [41,] 48.105819547
## [42,] 69.080305612
## [43,] 51.388867549
## [44,] 19.935743907
## [45,] 28.564068489
## [46,] 97.869505803
## [47,] 25.310351886
## [48,] 71.005293960
## [49,] 76.052088663
## [50,] 51.901613013
## 
## $model.list
## $model.list$response
## [1] "Output"
## 
## $model.list$variables
## [1] "Input"
## 
## 
## $err.fct
## function (x, y) 
## {
##     1/2 * (y - x)^2
## }
## <environment: 0x7f9b4da3c3c0>
## attr(,"type")
## [1] "sse"
## 
## $act.fct
## function (x) 
## {
##     1/(1 + exp(-x))
## }
## <environment: 0x7f9b4da3c3c0>
## attr(,"type")
## [1] "logistic"
## 
## $linear.output
## [1] TRUE
## 
## $data
##           Input       Output
## 1  32.020394178 5.6586565701
## 2  47.709458717 6.9072033934
## 3   2.075933246 1.4408099271
## 4  23.088465747 4.8050458632
## 5  17.389794486 4.1701072511
## 6  57.289577858 7.5689879018
## 7  73.695793655 8.5846254231
## 8  71.537656034 8.4579936175
## 9  22.925325111 4.7880397983
## 10  9.825203288 3.1345180313
## 11 58.742997167 7.6643980303
## 12 37.967556715 6.1617819432
## 13 65.326249506 8.0824655586
## 14 71.316806204 8.4449278389
## 15 43.390103057 6.5871164448
## 16 28.318706178 5.3215323149
## 17 47.166754538 6.8678056567
## 18 99.955119193 9.9977557078
## 19  7.547106617 2.7471997774
## 20 20.664367522 4.5458076864
## 21 65.056598489 8.0657670738
## 22 88.714478980 9.4188363920
## 23 97.980928328 9.8985316248
## 24 13.625274133 3.6912428981
## 25 47.331323614 6.8797764218
## 26 66.857404797 8.1766377440
## 27  4.705917975 2.1693127886
## 28 97.418323439 9.8700721091
## 29 19.307714095 4.3940544029
## 30  0.488112052 0.6986501642
## 31 29.529741197 5.4341274550
## 32  0.794723467 0.8914726395
## 33 80.710551864 8.9839051567
## 34  8.184401505 2.8608393007
## 35 36.370230094 6.0307735900
## 36 34.026908432 5.8332588175
## 37 68.704663473 8.2888276296
## 38 29.182307259 5.4020650921
## 39 93.623968866 9.6759479570
## 40 23.585942388 4.8565360482
## 41 48.105819547 6.9358358939
## 42 69.080305612 8.3114562871
## 43 51.388867549 7.1686029008
## 44 19.935743907 4.4649461258
## 45 28.564068489 5.3445363212
## 46 97.869505803 9.8929017888
## 47 25.310351886 5.0309394635
## 48 71.005293960 8.4264639060
## 49 76.052088663 8.7207848651
## 50 51.901613013 7.2042774109
## 
## $net.result
## $net.result[[1]]
##            [,1]
## 1  5.6621537751
## 2  6.9056076568
## 3  1.4474857448
## 4  4.8030852724
## 5  4.1684856260
## 6  7.5646695213
## 7  8.5877641101
## 8  8.4594866789
## 9  4.7859836916
## 10 3.1389915500
## 11 7.6601245389
## 12 6.1649697893
## 13 8.0800652494
## 14 8.4462578454
## 15 6.5878144374
## 16 5.3233016060
## 17 6.8664830252
## 18 9.9875611836
## 19 2.7454399026
## 20 4.5429177465
## 21 8.0632389353
## 22 9.4286789516
## 23 9.8946434140
## 24 3.6946811421
## 25 6.8783701902
## 26 8.1750371142
## 27 2.1652262538
## 28 9.8677276083
## 29 4.3912714020
## 30 0.7063490647
## 31 5.4366168326
## 32 0.8798252878
## 33 8.9921885226
## 34 2.8612260787
## 35 6.0343792094
## 36 5.8370576734
## 37 8.2883447978
## 38 5.4043616024
## 39 9.6813791253
## 40 4.8548870457
## 41 6.9340457262
## 42 8.3112190049
## 43 7.1654192632
## 44 4.4620456615
## 45 5.3464619210
## 46 9.8893279381
## 47 5.0305266423
## 48 8.4275661242
## 49 8.7257635028
## 50 7.2009185464
## 
## 
## $weights
## $weights[[1]]
## $weights[[1]][[1]]
##                [,1]          [,2]          [,3]          [,4]
## [1,] -0.24145770342 0.46565249908 33.0828716157  0.5565106656
## [2,]  0.02548932636 0.02589470117  0.6050453134 -0.2742337482
##                [,5]           [,6]           [,7]          [,8]
## [1,]  1.88645228830  4.17523615014 -0.37298711018 -0.3950749876
## [2,] -0.03040613891 -0.04366283876  0.03112594144 -0.9849034445
##                [,9]         [,10]
## [1,] -0.82788801765 -0.5868379277
## [2,]  0.09490032064  0.0323305187
## 
## $weights[[1]][[2]]
##                [,1]
##  [1,]  1.8743320490
##  [2,]  1.6272348458
##  [3,]  1.3887794444
##  [4,] -0.7089899392
##  [5,] -1.6598345310
##  [6,] -1.4390590900
##  [7,] -2.0944648794
##  [8,]  2.6163213518
##  [9,] -1.8181337538
## [10,]  1.9759761789
## [11,]  3.0813900940
## 
## 
## 
## $startweights
## $startweights[[1]]
## $startweights[[1]][[1]]
##                [,1]         [,2]          [,3]          [,4]         [,5]
## [1,] -0.06105560078 1.1590418039 -0.9333096526 -0.5837714122 1.2338707447
## [2,] -0.12415274869 0.5833508586  1.4042321652 -0.9798528421 0.1106241783
##               [,6]         [,7]         [,8]         [,9]        [,10]
## [1,]  1.1900922111 0.3203755725 -1.073654117 0.3621748117 0.2405254397
## [2,] -0.3569927991 0.7227005076 -2.780728020 1.2217977704 0.8631004820
## 
## $startweights[[1]][[2]]
##                 [,1]
##  [1,]  1.04020365509
##  [2,]  0.49718016625
##  [3,]  0.80994378521
##  [4,] -1.54311833317
##  [5,]  0.32872687478
##  [6,] -0.93026502726
##  [7,] -1.37277567776
##  [8,]  0.58023108360
##  [9,]  0.09428493705
## [10,]  1.14282121068
## [11,]  1.15549324682
## 
## 
## 
## $generalized.weights
## $generalized.weights[[1]]
##                [,1]
## 1  -0.0033572799842
## 2  -0.0017628459901
## 3  -0.5511319988853
## 4  -0.0057292506819
## 5  -0.0090078462348
## 6  -0.0013299271530
## 7  -0.0009057719935
## 8  -0.0009485504594
## 9  -0.0057948815099
## 10 -0.0239909402157
## 11 -0.0012802324651
## 12 -0.0025382337867
## 13 -0.0010897859561
## 14 -0.0009530881229
## 15 -0.0020473665303
## 16 -0.0041107082024
## 17 -0.0017946802007
## 18 -0.0005174943784
## 19 -0.0386930640789
## 20 -0.0068409767130
## 21 -0.0010966483902
## 22 -0.0006632647295
## 23 -0.0005416687216
## 24 -0.0134626007109
## 25 -0.0017849207954
## 26 -0.0010520885452
## 27 -0.0896489296635
## 28 -0.0005486610018
## 29 -0.0076218290295
## 30  2.8389173047094
## 31 -0.0038370034376
## 32  5.1241159749755
## 33 -0.0007828015770
## 34 -0.0334288089308
## 35 -0.0027226687440
## 36 -0.0030372215773
## 37 -0.0010092680731
## 38 -0.0039125292865
## 39 -0.0005970627860
## 40 -0.0055360883997
## 41 -0.0017402169371
## 42 -0.0010008887499
## 43 -0.0015707958843
## 44 -0.0072432856010
## 45 -0.0040528309734
## 46 -0.0005430498598
## 47 -0.0049389406852
## 48 -0.0009595420602
## 49 -0.0008619916045
## 50 -0.0015469341230
## 
## 
## $result.matrix
##                                         1
## error                     0.0004264838866
## reached.threshold         0.0098425215610
## steps                  3482.0000000000000
## Intercept.to.1layhid1    -0.2414577034225
## Input.to.1layhid1         0.0254893263634
## Intercept.to.1layhid2     0.4656524990802
## Input.to.1layhid2         0.0258947011675
## Intercept.to.1layhid3    33.0828716156795
## Input.to.1layhid3         0.6050453134430
## Intercept.to.1layhid4     0.5565106656090
## Input.to.1layhid4        -0.2742337482382
## Intercept.to.1layhid5     1.8864522883024
## Input.to.1layhid5        -0.0304061389055
## Intercept.to.1layhid6     4.1752361501376
## Input.to.1layhid6        -0.0436628387606
## Intercept.to.1layhid7    -0.3729871101768
## Input.to.1layhid7         0.0311259414365
## Intercept.to.1layhid8    -0.3950749875727
## Input.to.1layhid8        -0.9849034444639
## Intercept.to.1layhid9    -0.8278880176482
## Input.to.1layhid9         0.0949003206355
## Intercept.to.1layhid10   -0.5868379276785
## Input.to.1layhid10        0.0323305186987
## Intercept.to.Output       1.8743320490132
## 1layhid.1.to.Output       1.6272348458316
## 1layhid.2.to.Output       1.3887794444289
## 1layhid.3.to.Output      -0.7089899392468
## 1layhid.4.to.Output      -1.6598345310496
## 1layhid.5.to.Output      -1.4390590900255
## 1layhid.6.to.Output      -2.0944648794383
## 1layhid.7.to.Output       2.6163213518048
## 1layhid.8.to.Output      -1.8181337537664
## 1layhid.9.to.Output       1.9759761788774
## 1layhid.10.to.Output      3.0813900939603
## 
## attr(,"class")
## [1] "nn"
```

```r
#Plot the neural network
plot(net.sqrt)
 
#Test the neural network on some training data
testdata <- as.data.frame((1:10)^2) #Generate some squared numbers
net.results <- compute(net.sqrt, testdata) #Run them through the neural network
 
#See what properties net.sqrt has
ls(net.results)
```

```
## [1] "net.result" "neurons"
```

```r
#see the results
print(net.results$net.result)
```

```
##               [,1]
##  [1,] 0.9876200398
##  [2,] 2.0000737696
##  [3,] 3.0027726457
##  [4,] 3.9999607232
##  [5,] 4.9993538467
##  [6,] 6.0036717130
##  [7,] 6.9977891790
##  [8,] 7.9970105478
##  [9,] 9.0084550689
## [10,] 9.9896453639
```

```r
#Display a better version of the results
cleanoutput <- cbind(testdata,sqrt(testdata),
                         as.data.frame(net.results$net.result))
colnames(cleanoutput) <- c("Input","Expected Output","Neural Net Output")
print(cleanoutput)
```

```
##    Input Expected Output Neural Net Output
## 1      1               1      0.9876200398
## 2      4               2      2.0000737696
## 3      9               3      3.0027726457
## 4     16               4      3.9999607232
## 5     25               5      4.9993538467
## 6     36               6      6.0036717130
## 7     49               7      6.9977891790
## 8     64               8      7.9970105478
## 9     81               9      9.0084550689
## 10   100              10      9.9896453639
```

*Acknowledgement: this example excercise was from* http://gekkoquant.com/2012/05/26/neural-networks-with-r-simple-example/ 

