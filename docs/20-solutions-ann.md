# Solutions ch. 10 - Artificial neural networks {#solutions-ann}

Solutions to exercises of chapter \@ref(ann).

## Exercise 1


```r
library("neuralnet")
 
#To create a neural network to perform square root

#Generate 50 random numbers uniformly distributed between 0 and 100
#And store them as a dataframe
traininginput <-  as.data.frame(runif(50, min=0, max=100))
trainingoutput <- sqrt(traininginput)
 
#Column bind the data into one variable
trainingdata <- cbind(traininginput,trainingoutput)
colnames(trainingdata) <- c("Input","Output")
 
#Train the neural network
#Will have 10 hidden layers
#Threshold is a numeric value specifying the threshold for the partial
#derivatives of the error function as stopping criteria.
net.sqrt <- neuralnet(Output~Input,trainingdata, hidden=10, threshold=0.01)
print(net.sqrt)
```

```
## $call
## neuralnet(formula = Output ~ Input, data = trainingdata, hidden = 10, 
##     threshold = 0.01)
## 
## $response
##         Output
## 1  9.870815185
## 2  6.445072618
## 3  7.199296037
## 4  9.303156736
## 5  8.284631898
## 6  4.397098213
## 7  6.397597538
## 8  9.400107047
## 9  8.937289266
## 10 5.427072308
## 11 8.743569638
## 12 6.407044286
## 13 9.865636051
## 14 5.539326476
## 15 6.805710498
## 16 5.920430657
## 17 6.633430219
## 18 7.017826068
## 19 7.347484084
## 20 8.584261769
## 21 9.974375955
## 22 3.757433403
## 23 3.476007912
## 24 8.917650914
## 25 8.582715932
## 26 4.400085105
## 27 8.519732664
## 28 1.799850747
## 29 4.353835702
## 30 5.708127624
## 31 6.664868578
## 32 7.217805067
## 33 7.217258518
## 34 5.564370816
## 35 5.452476458
## 36 6.851944707
## 37 6.178945252
## 38 3.353516466
## 39 9.875358361
## 40 3.552082160
## 41 3.717583465
## 42 7.668066085
## 43 7.092453280
## 44 5.353054657
## 45 7.913856138
## 46 8.871669241
## 47 9.668303180
## 48 7.581193245
## 49 9.710259022
## 50 6.506383418
## 
## $covariate
##               [,1]
##  [1,] 97.432992421
##  [2,] 41.538961045
##  [3,] 51.829863433
##  [4,] 86.548725259
##  [5,] 68.635125691
##  [6,] 19.334472693
##  [7,] 40.929254261
##  [8,] 88.362012501
##  [9,] 79.875139426
## [10,] 29.453113838
## [11,] 76.450010017
## [12,] 41.050216486
## [13,] 97.330774693
## [14,] 30.684137810
## [15,] 46.317695384
## [16,] 35.051499167
## [17,] 44.002396474
## [18,] 49.249882717
## [19,] 53.985522361
## [20,] 73.689550115
## [21,] 99.488175684
## [22,] 14.118305780
## [23,] 12.082631001
## [24,] 79.524497828
## [25,] 73.663012777
## [26,] 19.360748935
## [27,] 72.585844668
## [28,]  3.239462711
## [29,] 18.955885316
## [30,] 32.582720974
## [31,] 44.420473161
## [32,] 52.096709982
## [33,] 52.088820515
## [34,] 30.962222582
## [35,] 29.729499528
## [36,] 46.949146269
## [37,] 38.179364428
## [38,] 11.246072687
## [39,] 97.522702767
## [40,] 12.617287668
## [41,] 13.820426818
## [42,] 58.799237479
## [43,] 50.302893529
## [44,] 28.655194165
## [45,] 62.629118981
## [46,] 78.706515115
## [47,] 93.476086389
## [48,] 57.474491023
## [49,] 94.289130275
## [50,] 42.333025183
## 
## $model.list
## $model.list$response
## [1] "Output"
## 
## $model.list$variables
## [1] "Input"
## 
## 
## $err.fct
## function (x, y) 
## {
##     1/2 * (y - x)^2
## }
## <environment: 0x457b250>
## attr(,"type")
## [1] "sse"
## 
## $act.fct
## function (x) 
## {
##     1/(1 + exp(-x))
## }
## <environment: 0x457b250>
## attr(,"type")
## [1] "logistic"
## 
## $linear.output
## [1] TRUE
## 
## $data
##           Input      Output
## 1  97.432992421 9.870815185
## 2  41.538961045 6.445072618
## 3  51.829863433 7.199296037
## 4  86.548725259 9.303156736
## 5  68.635125691 8.284631898
## 6  19.334472693 4.397098213
## 7  40.929254261 6.397597538
## 8  88.362012501 9.400107047
## 9  79.875139426 8.937289266
## 10 29.453113838 5.427072308
## 11 76.450010017 8.743569638
## 12 41.050216486 6.407044286
## 13 97.330774693 9.865636051
## 14 30.684137810 5.539326476
## 15 46.317695384 6.805710498
## 16 35.051499167 5.920430657
## 17 44.002396474 6.633430219
## 18 49.249882717 7.017826068
## 19 53.985522361 7.347484084
## 20 73.689550115 8.584261769
## 21 99.488175684 9.974375955
## 22 14.118305780 3.757433403
## 23 12.082631001 3.476007912
## 24 79.524497828 8.917650914
## 25 73.663012777 8.582715932
## 26 19.360748935 4.400085105
## 27 72.585844668 8.519732664
## 28  3.239462711 1.799850747
## 29 18.955885316 4.353835702
## 30 32.582720974 5.708127624
## 31 44.420473161 6.664868578
## 32 52.096709982 7.217805067
## 33 52.088820515 7.217258518
## 34 30.962222582 5.564370816
## 35 29.729499528 5.452476458
## 36 46.949146269 6.851944707
## 37 38.179364428 6.178945252
## 38 11.246072687 3.353516466
## 39 97.522702767 9.875358361
## 40 12.617287668 3.552082160
## 41 13.820426818 3.717583465
## 42 58.799237479 7.668066085
## 43 50.302893529 7.092453280
## 44 28.655194165 5.353054657
## 45 62.629118981 7.913856138
## 46 78.706515115 8.871669241
## 47 93.476086389 9.668303180
## 48 57.474491023 7.581193245
## 49 94.289130275 9.710259022
## 50 42.333025183 6.506383418
## 
## $net.result
## $net.result[[1]]
##           [,1]
## 1  9.866606194
## 2  6.446307173
## 3  7.196129138
## 4  9.309306122
## 5  8.283871113
## 6  4.394415587
## 7  6.399074128
## 8  9.405745373
## 9  8.942530355
## 10 5.428425265
## 11 8.747219538
## 12 6.408474006
## 13 9.861619085
## 14 5.541199378
## 15 6.804767187
## 16 5.923154619
## 17 6.633576232
## 18 7.015586191
## 19 7.343769461
## 20 8.586371228
## 21 9.965850586
## 22 3.757219159
## 23 3.476811306
## 24 8.922753704
## 25 8.584810053
## 26 4.397399626
## 27 8.521201238
## 28 1.799654760
## 29 4.351207471
## 30 5.710572935
## 31 6.664819060
## 32 7.214558082
## 33 7.214013854
## 34 5.566345902
## 35 5.453955162
## 36 6.850708503
## 37 6.181291830
## 38 3.354502970
## 39 9.870979114
## 40 3.552685528
## 41 3.717552883
## 42 7.664047581
## 43 7.089804127
## 44 5.354019109
## 45 7.910550458
## 46 8.876424680
## 47 9.670075917
## 48 7.577124308
## 49 9.711035912
## 50 6.507283430
## 
## 
## $weights
## $weights[[1]]
## $weights[[1]][[1]]
##               [,1]           [,2]          [,3]          [,4]
## [1,]  0.2903191899 -2.14321235454 -0.1856405456 0.28950181668
## [2,] -0.2389492896  0.02508701701 -0.8145854136 0.04035398887
##                [,5]          [,6]           [,7]           [,8]
## [1,] -0.03307737813 1.05744721172  0.65718627617 -0.21592691951
## [2,] -0.02627096446 0.07098591778 -0.08093475618 -0.02047353071
##              [,9]          [,10]
## [1,] 5.7609366248  0.67599142867
## [2,] 0.2205606231 -0.02426723343
## 
## $weights[[1]][[2]]
##               [,1]
##  [1,]  1.434410826
##  [2,] -1.527376080
##  [3,]  5.110647796
##  [4,] -1.807365682
##  [5,]  2.609549619
##  [6,] -1.015124554
##  [7,]  1.961668356
##  [8,] -1.638159810
##  [9,] -1.218167973
## [10,]  1.732308198
## [11,] -3.704585922
## 
## 
## 
## $startweights
## $startweights[[1]]
## $startweights[[1]][[1]]
##              [,1]          [,2]          [,3]          [,4]          [,5]
## [1,] -1.035260238 -0.8493857059 -0.8240445708 0.39681697369 -0.8548144264
## [2,] -1.161472165  0.8124601427 -0.7893146313 0.08297549367 -0.7740204976
##               [,6]          [,7]          [,8]          [,9]         [,10]
## [1,] -0.2157857076 -0.4201349595 -0.8394359854  1.9080592472 -0.6171048144
## [2,] -0.6776242303 -1.0731546923 -0.1284181586 -0.4981557002 -1.1131134197
## 
## $startweights[[1]][[2]]
##                  [,1]
##  [1,]  0.076403442120
##  [2,] -0.171741187037
##  [3,] -0.009127980661
##  [4,]  0.844474273092
##  [5,]  0.817753127844
##  [6,] -0.306543449084
##  [7,]  1.122394720469
##  [8,] -0.039391259218
##  [9,] -0.679606053606
## [10,]  0.381618388172
## [11,] -2.570405760713
## 
## 
## 
## $generalized.weights
## $generalized.weights[[1]]
##                [,1]
## 1  -0.0005574268033
## 2  -0.0021980478803
## 3  -0.0015507484988
## 4  -0.0006925290670
## 5  -0.0010090181011
## 6  -0.0076157745992
## 7  -0.0022509816354
## 8  -0.0006678017148
## 9  -0.0007930885734
## 10 -0.0038517811427
## 11 -0.0008516506871
## 12 -0.0022403069698
## 13 -0.0005585611227
## 14 -0.0036020878707
## 15 -0.0018481059646
## 16 -0.0028963171519
## 17 -0.0020045135989
## 18 -0.0016785788276
## 19 -0.0014564395486
## 20 -0.0009030485597
## 21 -0.0005350914392
## 22 -0.0127846152746
## 23 -0.0166670575139
## 24 -0.0007988433252
## 25 -0.0009035628686
## 26 -0.0075990595107
## 27 -0.0009247866615
## 28 -0.2024918265785
## 29 -0.0078635530423
## 30 -0.0032645177642
## 31 -0.0019745921909
## 32 -0.0015385020661
## 33 -0.0015388617062
## 34 -0.0035492395435
## 35 -0.0037933787099
## 36 -0.0018091192726
## 37 -0.0025192354978
## 38 -0.0188622089866
## 39 -0.0005564331437
## 40 -0.0154741566827
## 41 -0.0132531431407
## 42 -0.0012782041536
## 43 -0.0016242433004
## 44 -0.0040286153741
## 45 -0.0011610666878
## 46 -0.0008124735780
## 47 -0.0006030574558
## 48 -0.0013233849762
## 49 -0.0005933840659
## 50 -0.0021322485025
## 
## 
## $result.matrix
##                                         1
## error                     0.0002321444841
## reached.threshold         0.0093605229627
## steps                  4887.0000000000000
## Intercept.to.1layhid1     0.2903191898586
## Input.to.1layhid1        -0.2389492896454
## Intercept.to.1layhid2    -2.1432123545367
## Input.to.1layhid2         0.0250870170075
## Intercept.to.1layhid3    -0.1856405455539
## Input.to.1layhid3        -0.8145854136198
## Intercept.to.1layhid4     0.2895018166834
## Input.to.1layhid4         0.0403539888697
## Intercept.to.1layhid5    -0.0330773781308
## Input.to.1layhid5        -0.0262709644575
## Intercept.to.1layhid6     1.0574472117243
## Input.to.1layhid6         0.0709859177815
## Intercept.to.1layhid7     0.6571862761718
## Input.to.1layhid7        -0.0809347561789
## Intercept.to.1layhid8    -0.2159269195064
## Input.to.1layhid8        -0.0204735307075
## Intercept.to.1layhid9     5.7609366248209
## Input.to.1layhid9         0.2205606230760
## Intercept.to.1layhid10    0.6759914286685
## Input.to.1layhid10       -0.0242672334304
## Intercept.to.Output       1.4344108257876
## 1layhid.1.to.Output      -1.5273760797002
## 1layhid.2.to.Output       5.1106477955879
## 1layhid.3.to.Output      -1.8073656823855
## 1layhid.4.to.Output       2.6095496186911
## 1layhid.5.to.Output      -1.0151245540148
## 1layhid.6.to.Output       1.9616683560635
## 1layhid.7.to.Output      -1.6381598100881
## 1layhid.8.to.Output      -1.2181679728290
## 1layhid.9.to.Output       1.7323081976103
## 1layhid.10.to.Output     -3.7045859223396
## 
## attr(,"class")
## [1] "nn"
```

```r
#Plot the neural network
plot(net.sqrt)
 
#Test the neural network on some training data
testdata <- as.data.frame((1:10)^2) #Generate some squared numbers
net.results <- compute(net.sqrt, testdata) #Run them through the neural network
 
#See what properties net.sqrt has
ls(net.results)
```

```
## [1] "net.result" "neurons"
```

```r
#see the results
print(net.results$net.result)
```

```
##               [,1]
##  [1,] 0.9277768875
##  [2,] 2.0056959238
##  [3,] 3.0008537235
##  [4,] 3.9985854265
##  [5,] 4.9989398555
##  [6,] 6.0026908328
##  [7,] 6.9978626108
##  [8,] 7.9971402323
##  [9,] 9.0056365961
## [10,] 9.9902604374
```

```r
#Display a better version of the results
cleanoutput <- cbind(testdata,sqrt(testdata),
                         as.data.frame(net.results$net.result))
colnames(cleanoutput) <- c("Input","Expected Output","Neural Net Output")
print(cleanoutput)
```

```
##    Input Expected Output Neural Net Output
## 1      1               1      0.9277768875
## 2      4               2      2.0056959238
## 3      9               3      3.0008537235
## 4     16               4      3.9985854265
## 5     25               5      4.9989398555
## 6     36               6      6.0026908328
## 7     49               7      6.9978626108
## 8     64               8      7.9971402323
## 9     81               9      9.0056365961
## 10   100              10      9.9902604374
```

*Acknowledgement: this example excercise was from* http://gekkoquant.com/2012/05/26/neural-networks-with-r-simple-example/ 

