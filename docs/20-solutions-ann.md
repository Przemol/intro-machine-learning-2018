# Solutions ch. 8 - Artificial neural networks {#solutions-ann}

Solutions to exercises of chapter \@ref(ann).

## Exercise 1


```r
library("neuralnet")
 
#To create a neural network to perform square root

#Generate 50 random numbers uniformly distributed between 0 and 100
#And store them as a dataframe
traininginput <-  as.data.frame(runif(50, min=0, max=100))
trainingoutput <- sqrt(traininginput)
 
#Column bind the data into one variable
trainingdata <- cbind(traininginput,trainingoutput)
colnames(trainingdata) <- c("Input","Output")
 
#Train the neural network
#Will have 10 hidden layers
#Threshold is a numeric value specifying the threshold for the partial
#derivatives of the error function as stopping criteria.
net.sqrt <- neuralnet(Output~Input,trainingdata, hidden=10, threshold=0.01)
print(net.sqrt)
```

```
## $call
## neuralnet(formula = Output ~ Input, data = trainingdata, hidden = 10, 
##     threshold = 0.01)
## 
## $response
##         Output
## 1  4.864785082
## 2  5.688787800
## 3  9.841962459
## 4  8.423977615
## 5  9.970143273
## 6  8.772880951
## 7  9.260188136
## 8  2.082286690
## 9  5.480761183
## 10 7.244742833
## 11 4.609793176
## 12 8.668789125
## 13 8.594293302
## 14 4.002700092
## 15 9.222878246
## 16 6.210429749
## 17 4.218733758
## 18 5.980204082
## 19 9.749389001
## 20 7.419435131
## 21 8.939723033
## 22 4.920640447
## 23 7.457318995
## 24 6.976142950
## 25 7.245205994
## 26 5.333278575
## 27 8.912937324
## 28 5.333495865
## 29 9.127336623
## 30 8.839482680
## 31 9.522763701
## 32 5.058027872
## 33 8.747505435
## 34 7.881812770
## 35 3.317430259
## 36 9.451081798
## 37 5.489925795
## 38 5.308168761
## 39 7.083297757
## 40 7.485382963
## 41 6.360650903
## 42 8.722949051
## 43 8.663122901
## 44 8.771228550
## 45 9.305034312
## 46 9.961542330
## 47 3.765151044
## 48 7.960550470
## 49 2.480855211
## 50 7.388777724
## 
## $covariate
##               [,1]
##  [1,] 23.666133895
##  [2,] 32.362306630
##  [3,] 96.864225040
##  [4,] 70.963398856
##  [5,] 99.403756880
##  [6,] 76.963440189
##  [7,] 85.751084308
##  [8,]  4.335917858
##  [9,] 30.038743140
## [10,] 52.486298722
## [11,] 21.250193124
## [12,] 75.147904898
## [13,] 73.861877364
## [14,] 16.021608026
## [15,] 85.061483132
## [16,] 38.569437666
## [17,] 17.797714518
## [18,] 35.762840859
## [19,] 95.050585899
## [20,] 55.048017669
## [21,] 79.918647907
## [22,] 24.212702410
## [23,] 55.611606594
## [24,] 48.666570452
## [25,] 52.493009903
## [26,] 28.443860356
## [27,] 79.440451739
## [28,] 28.446178138
## [29,] 83.308273833
## [30,] 78.136454057
## [31,] 90.683028498
## [32,] 25.583645958
## [33,] 76.518851332
## [34,] 62.122972542
## [35,] 11.005343520
## [36,] 89.322947152
## [37,] 30.139285233
## [38,] 28.176655597
## [39,] 50.173107116
## [40,] 56.030958099
## [41,] 40.457879915
## [42,] 76.089840150
## [43,] 75.049698399
## [44,] 76.934450283
## [45,] 86.583663546
## [46,] 99.232325586
## [47,] 14.176362380
## [48,] 63.370363787
## [49,]  6.154642580
## [50,] 54.594036262
## 
## $model.list
## $model.list$response
## [1] "Output"
## 
## $model.list$variables
## [1] "Input"
## 
## 
## $err.fct
## function (x, y) 
## {
##     1/2 * (y - x)^2
## }
## <environment: 0x7fc4ae777d10>
## attr(,"type")
## [1] "sse"
## 
## $act.fct
## function (x) 
## {
##     1/(1 + exp(-x))
## }
## <environment: 0x7fc4ae777d10>
## attr(,"type")
## [1] "logistic"
## 
## $linear.output
## [1] TRUE
## 
## $data
##           Input      Output
## 1  23.666133895 4.864785082
## 2  32.362306630 5.688787800
## 3  96.864225040 9.841962459
## 4  70.963398856 8.423977615
## 5  99.403756880 9.970143273
## 6  76.963440189 8.772880951
## 7  85.751084308 9.260188136
## 8   4.335917858 2.082286690
## 9  30.038743140 5.480761183
## 10 52.486298722 7.244742833
## 11 21.250193124 4.609793176
## 12 75.147904898 8.668789125
## 13 73.861877364 8.594293302
## 14 16.021608026 4.002700092
## 15 85.061483132 9.222878246
## 16 38.569437666 6.210429749
## 17 17.797714518 4.218733758
## 18 35.762840859 5.980204082
## 19 95.050585899 9.749389001
## 20 55.048017669 7.419435131
## 21 79.918647907 8.939723033
## 22 24.212702410 4.920640447
## 23 55.611606594 7.457318995
## 24 48.666570452 6.976142950
## 25 52.493009903 7.245205994
## 26 28.443860356 5.333278575
## 27 79.440451739 8.912937324
## 28 28.446178138 5.333495865
## 29 83.308273833 9.127336623
## 30 78.136454057 8.839482680
## 31 90.683028498 9.522763701
## 32 25.583645958 5.058027872
## 33 76.518851332 8.747505435
## 34 62.122972542 7.881812770
## 35 11.005343520 3.317430259
## 36 89.322947152 9.451081798
## 37 30.139285233 5.489925795
## 38 28.176655597 5.308168761
## 39 50.173107116 7.083297757
## 40 56.030958099 7.485382963
## 41 40.457879915 6.360650903
## 42 76.089840150 8.722949051
## 43 75.049698399 8.663122901
## 44 76.934450283 8.771228550
## 45 86.583663546 9.305034312
## 46 99.232325586 9.961542330
## 47 14.176362380 3.765151044
## 48 63.370363787 7.960550470
## 49  6.154642580 2.480855211
## 50 54.594036262 7.388777724
## 
## $net.result
## $net.result[[1]]
##           [,1]
## 1  4.858668092
## 2  5.692726682
## 3  9.837717275
## 4  8.420136394
## 5  9.959193884
## 6  8.774074427
## 7  9.266482744
## 8  2.091545749
## 9  5.481300750
## 10 7.243260618
## 11 4.604685713
## 12 8.668409486
## 13 8.592800749
## 14 4.007122604
## 15 9.229053028
## 16 6.219510846
## 17 4.219337657
## 18 5.987906091
## 19 9.748816745
## 20 7.415536578
## 21 8.943289062
## 22 4.914650307
## 23 7.452958884
## 24 6.978821598
## 25 7.243716881
## 26 5.331457119
## 27 8.916146997
## 28 5.331677708
## 29 9.132927865
## 30 8.841660171
## 31 9.527644455
## 32 5.052851275
## 33 8.748317072
## 34 7.874561284
## 35 3.321763714
## 36 9.456796351
## 37 5.490617156
## 38 5.305971040
## 39 7.084303840
## 40 7.480698517
## 41 6.369713222
## 42 8.723389352
## 43 8.662657742
## 44 8.772397243
## 45 9.311381473
## 46 9.951105621
## 47 3.772495039
## 48 7.953302274
## 49 2.466055003
## 50 7.385271250
## 
## 
## $weights
## $weights[[1]]
## $weights[[1]][[1]]
##              [,1]          [,2]           [,3]          [,4]
## [1,] 1.4550729531 -0.6266100664  1.58131462330 1.01088028261
## [2,] 0.0213577411  0.2351523436 -0.02656914718 0.02601815772
##                [,5]           [,6]           [,7]        [,8]
## [1,]  0.12225501643 -1.93359925200 -2.01850716562 0.369786300
## [2,] -0.03410016533  0.02706439773  0.02745389652 0.113269615
##                [,9]        [,10]
## [1,]  1.96478563264 0.5559017682
## [2,] -0.09261412244 0.1039108555
## 
## $weights[[1]][[2]]
##                [,1]
##  [1,] -1.0336783303
##  [2,]  0.7067148795
##  [3,]  1.6715203284
##  [4,] -1.0769537822
##  [5,]  2.7760554623
##  [6,] -1.6969898616
##  [7,]  4.0072705417
##  [8,]  2.2544423265
##  [9,]  0.8250579677
## [10,] -1.3986730731
## [11,]  1.2081069855
## 
## 
## 
## $startweights
## $startweights[[1]]
## $startweights[[1]][[1]]
##               [,1]          [,2]          [,3]          [,4]          [,5]
## [1,]  0.6562496101 -0.7639517663  1.1254192205  0.1604934063 -0.3875258151
## [2,] -0.8296284264  0.7923786131 -0.4537112424 -0.8423371402 -0.6023798453
##               [,6]          [,7]         [,8]          [,9]         [,10]
## [1,] -1.9840289728 -1.3555086326 0.6425704156  0.9055211232 -0.7323631771
## [2,] -0.2686196615  0.6384884939 0.7666294814 -0.7432680920 -0.7519117373
## 
## $startweights[[1]][[2]]
##                 [,1]
##  [1,] -1.89061151584
##  [2,]  0.11291841470
##  [3,]  0.81454237955
##  [4,] -0.56179025665
##  [5,]  2.21267413786
##  [6,] -1.16477917626
##  [7,]  0.53603982542
##  [8,]  0.25806386901
##  [9,] -0.74250117229
## [10,] -1.31911549971
## [11,]  0.09884603212
## 
## 
## 
## $generalized.weights
## $generalized.weights[[1]]
##                [,1]
## 1  -0.0054885462002
## 2  -0.0033413475813
## 3  -0.0005581741979
## 4  -0.0009619624741
## 5  -0.0005282416951
## 6  -0.0008480885512
## 7  -0.0007065101241
## 8  -0.0927186763996
## 9  -0.0037754568100
## 10 -0.0015034317402
## 11 -0.0064760847696
## 12 -0.0008807973903
## 13 -0.0009048323596
## 14 -0.0101983172763
## 15 -0.0007167490372
## 16 -0.0024858398079
## 17 -0.0085670564525
## 18 -0.0028258848921
## 19 -0.0005804003734
## 20 -0.0013987789669
## 21 -0.0007976014749
## 22 -0.0052993432475
## 23 -0.0013776250057
## 24 -0.0016912571291
## 25 -0.0015031376538
## 26 -0.0041213522573
## 27 -0.0008055554471
## 28 -0.0041208172651
## 29 -0.0007433956552
## 30 -0.0008276603302
## 31 -0.0006369843943
## 32 -0.0048674803215
## 33 -0.0008559723020
## 34 -0.0011705654672
## 35 -0.0199622545987
## 36 -0.0006555339149
## 37 -0.0037550555324
## 38 -0.0041837043398
## 39 -0.0016119710864
## 40 -0.0013622792335
## 41 -0.0022923721874
## 42 -0.0008636559992
## 43 -0.0008826065807
## 44 -0.0008486002067
## 45 -0.0006943242193
## 46 -0.0005302195827
## 47 -0.0126050685958
## 48 -0.0011371061281
## 49 -0.0550742765266
## 50 -0.0014162795693
## 
## 
## $result.matrix
##                                         1
## error                     0.0007315509792
## reached.threshold         0.0088203167474
## steps                  5357.0000000000000
## Intercept.to.1layhid1     1.4550729530521
## Input.to.1layhid1         0.0213577410964
## Intercept.to.1layhid2    -0.6266100663908
## Input.to.1layhid2         0.2351523436056
## Intercept.to.1layhid3     1.5813146233037
## Input.to.1layhid3        -0.0265691471844
## Intercept.to.1layhid4     1.0108802826132
## Input.to.1layhid4         0.0260181577242
## Intercept.to.1layhid5     0.1222550164267
## Input.to.1layhid5        -0.0341001653340
## Intercept.to.1layhid6    -1.9335992519981
## Input.to.1layhid6         0.0270643977341
## Intercept.to.1layhid7    -2.0185071656190
## Input.to.1layhid7         0.0274538965194
## Intercept.to.1layhid8     0.3697862999934
## Input.to.1layhid8         0.1132696150089
## Intercept.to.1layhid9     1.9647856326429
## Input.to.1layhid9        -0.0926141224426
## Intercept.to.1layhid10    0.5559017682433
## Input.to.1layhid10        0.1039108555481
## Intercept.to.Output      -1.0336783302993
## 1layhid.1.to.Output       0.7067148795294
## 1layhid.2.to.Output       1.6715203283585
## 1layhid.3.to.Output      -1.0769537822149
## 1layhid.4.to.Output       2.7760554623461
## 1layhid.5.to.Output      -1.6969898616132
## 1layhid.6.to.Output       4.0072705417266
## 1layhid.7.to.Output       2.2544423265036
## 1layhid.8.to.Output       0.8250579676862
## 1layhid.9.to.Output      -1.3986730731178
## 1layhid.10.to.Output      1.2081069855162
## 
## attr(,"class")
## [1] "nn"
```

```r
#Plot the neural network
plot(net.sqrt)
 
#Test the neural network on some training data
testdata <- as.data.frame((1:10)^2) #Generate some squared numbers
net.results <- compute(net.sqrt, testdata) #Run them through the neural network
 
#See what properties net.sqrt has
ls(net.results)
```

```
## [1] "net.result" "neurons"
```

```r
#see the results
print(net.results$net.result)
```

```
##              [,1]
##  [1,] 1.373991258
##  [2,] 2.020171382
##  [3,] 2.995137651
##  [4,] 4.004466240
##  [5,] 4.994396379
##  [6,] 6.007883946
##  [7,] 7.002309389
##  [8,] 7.992820846
##  [9,] 9.004316644
## [10,] 9.987197494
```

```r
#Display a better version of the results
cleanoutput <- cbind(testdata,sqrt(testdata),
                         as.data.frame(net.results$net.result))
colnames(cleanoutput) <- c("Input","Expected Output","Neural Net Output")
print(cleanoutput)
```

```
##    Input Expected Output Neural Net Output
## 1      1               1       1.373991258
## 2      4               2       2.020171382
## 3      9               3       2.995137651
## 4     16               4       4.004466240
## 5     25               5       4.994396379
## 6     36               6       6.007883946
## 7     49               7       7.002309389
## 8     64               8       7.992820846
## 9     81               9       9.004316644
## 10   100              10       9.987197494
```

*Acknowledgement: this example excercise was from* http://gekkoquant.com/2012/05/26/neural-networks-with-r-simple-example/ 

