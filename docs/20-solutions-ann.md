# Solutions ch. 8 - Artificial neural networks {#solutions-ann}

Solutions to exercises of chapter \@ref(ann).

## Exercise 1


```r
library("neuralnet")
 
#To create a neural network to perform square root

#Generate 50 random numbers uniformly distributed between 0 and 100
#And store them as a dataframe
traininginput <-  as.data.frame(runif(50, min=0, max=100))
trainingoutput <- sqrt(traininginput)
 
#Column bind the data into one variable
trainingdata <- cbind(traininginput,trainingoutput)
colnames(trainingdata) <- c("Input","Output")
 
#Train the neural network
#Will have 10 hidden layers
#Threshold is a numeric value specifying the threshold for the partial
#derivatives of the error function as stopping criteria.
net.sqrt <- neuralnet(Output~Input,trainingdata, hidden=10, threshold=0.01)
print(net.sqrt)
```

```
## $call
## neuralnet(formula = Output ~ Input, data = trainingdata, hidden = 10, 
##     threshold = 0.01)
## 
## $response
##         Output
## 1  8.494968085
## 2  9.374356568
## 3  1.971263110
## 4  9.141706543
## 5  6.094227010
## 6  9.748509668
## 7  1.888853862
## 8  8.345805769
## 9  8.439378026
## 10 8.123513552
## 11 8.485188353
## 12 7.994667731
## 13 9.938204765
## 14 8.064168202
## 15 3.787135926
## 16 3.458889032
## 17 5.267649231
## 18 5.050313835
## 19 7.935387004
## 20 7.159019617
## 21 6.152285799
## 22 8.442986284
## 23 6.931592745
## 24 8.161229831
## 25 2.540220877
## 26 9.135983264
## 27 1.143529050
## 28 3.479072276
## 29 6.730975733
## 30 4.695917274
## 31 9.850478837
## 32 1.405611158
## 33 4.399637056
## 34 5.998941735
## 35 7.464000767
## 36 6.135377710
## 37 5.842553707
## 38 7.966342792
## 39 4.866882598
## 40 9.646413903
## 41 4.018333111
## 42 9.092741928
## 43 8.635811627
## 44 7.823783284
## 45 4.436574991
## 46 8.664164985
## 47 7.488725144
## 48 5.283070290
## 49 5.508611051
## 50 8.844307252
## 
## $covariate
##               [,1]
##  [1,] 72.164482763
##  [2,] 87.878561066
##  [3,]  3.885878250
##  [4,] 83.570798510
##  [5,] 37.139602844
##  [6,] 95.033440739
##  [7,]  3.567768913
##  [8,] 69.652473927
##  [9,] 71.223101462
## [10,] 65.991472430
## [11,] 71.998421382
## [12,] 63.914712123
## [13,] 98.767913948
## [14,] 65.030808793
## [15,] 14.342398522
## [16,] 11.963913334
## [17,] 27.748128423
## [18,] 25.505669834
## [19,] 62.970366911
## [20,] 51.251561870
## [21,] 37.850620551
## [22,] 71.284017386
## [23,] 48.046977981
## [24,] 66.605672357
## [25,]  6.452722102
## [26,] 83.466190193
## [27,]  1.307658688
## [28,] 12.103943899
## [29,] 45.306034316
## [30,] 22.051639040
## [31,] 97.031933325
## [32,]  1.975742728
## [33,] 19.356806227
## [34,] 35.987301939
## [35,] 55.711307446
## [36,] 37.642859644
## [37,] 34.135433822
## [38,] 63.462617481
## [39,] 23.686546227
## [40,] 93.053301191
## [41,] 16.147000995
## [42,] 82.677955762
## [43,] 74.577242462
## [44,] 61.211584881
## [45,] 19.683197653
## [46,] 75.067754881
## [47,] 56.081004278
## [48,] 27.910831687
## [49,] 30.344795715
## [50,] 78.221770772
## 
## $model.list
## $model.list$response
## [1] "Output"
## 
## $model.list$variables
## [1] "Input"
## 
## 
## $err.fct
## function (x, y) 
## {
##     1/2 * (y - x)^2
## }
## <environment: 0x7fbbb5adebc0>
## attr(,"type")
## [1] "sse"
## 
## $act.fct
## function (x) 
## {
##     1/(1 + exp(-x))
## }
## <environment: 0x7fbbb5adebc0>
## attr(,"type")
## [1] "logistic"
## 
## $linear.output
## [1] TRUE
## 
## $data
##           Input      Output
## 1  72.164482763 8.494968085
## 2  87.878561066 9.374356568
## 3   3.885878250 1.971263110
## 4  83.570798510 9.141706543
## 5  37.139602844 6.094227010
## 6  95.033440739 9.748509668
## 7   3.567768913 1.888853862
## 8  69.652473927 8.345805769
## 9  71.223101462 8.439378026
## 10 65.991472430 8.123513552
## 11 71.998421382 8.485188353
## 12 63.914712123 7.994667731
## 13 98.767913948 9.938204765
## 14 65.030808793 8.064168202
## 15 14.342398522 3.787135926
## 16 11.963913334 3.458889032
## 17 27.748128423 5.267649231
## 18 25.505669834 5.050313835
## 19 62.970366911 7.935387004
## 20 51.251561870 7.159019617
## 21 37.850620551 6.152285799
## 22 71.284017386 8.442986284
## 23 48.046977981 6.931592745
## 24 66.605672357 8.161229831
## 25  6.452722102 2.540220877
## 26 83.466190193 9.135983264
## 27  1.307658688 1.143529050
## 28 12.103943899 3.479072276
## 29 45.306034316 6.730975733
## 30 22.051639040 4.695917274
## 31 97.031933325 9.850478837
## 32  1.975742728 1.405611158
## 33 19.356806227 4.399637056
## 34 35.987301939 5.998941735
## 35 55.711307446 7.464000767
## 36 37.642859644 6.135377710
## 37 34.135433822 5.842553707
## 38 63.462617481 7.966342792
## 39 23.686546227 4.866882598
## 40 93.053301191 9.646413903
## 41 16.147000995 4.018333111
## 42 82.677955762 9.092741928
## 43 74.577242462 8.635811627
## 44 61.211584881 7.823783284
## 45 19.683197653 4.436574991
## 46 75.067754881 8.664164985
## 47 56.081004278 7.488725144
## 48 27.910831687 5.283070290
## 49 30.344795715 5.508611051
## 50 78.221770772 8.844307252
## 
## $net.result
## $net.result[[1]]
##           [,1]
## 1  8.493524304
## 2  9.380253381
## 3  1.969989863
## 4  9.146353408
## 5  6.094523865
## 6  9.749036322
## 7  1.888268511
## 8  8.343781654
## 9  8.437665677
## 10 8.121420381
## 11 8.483692842
## 12 7.992903611
## 13 9.929786348
## 14 8.062197896
## 15 3.785930666
## 16 3.459699943
## 17 5.267619002
## 18 5.050662795
## 19 7.933844528
## 20 7.161124835
## 21 6.152770365
## 22 8.441289484
## 23 6.934027991
## 24 8.159086917
## 25 2.541167213
## 26 9.140577853
## 27 1.142635407
## 28 3.479718276
## 29 6.733258833
## 30 4.696328286
## 31 9.846868451
## 32 1.407418461
## 33 4.399286758
## 34 5.998964445
## 35 7.464889324
## 36 6.135806279
## 37 5.842248425
## 38 7.964679775
## 39 4.867391792
## 40 9.649739937
## 41 4.016899071
## 42 9.096921470
## 43 8.635317056
## 44 7.822747391
## 45 4.436349444
## 46 8.663904870
## 47 7.489486876
## 48 5.283011747
## 49 5.508220357
## 50 8.845802268
## 
## 
## $weights
## $weights[[1]]
## $weights[[1]][[1]]
##              [,1]          [,2]           [,3]          [,4]
## [1,] 0.2019765556  1.8315334821 -0.76151502769  0.9377987226
## [2,] 0.2875546643 -0.1670601836  0.04852142138 -0.3309593486
##                [,5]           [,6]           [,7]           [,8]
## [1,] -0.41405700742 -1.17074876859 -0.02065294918  0.84226100503
## [2,] -0.04902720879  0.04103485194  0.03761262059 -0.05130308636
##               [,9]          [,10]
## [1,] -1.2146627116 -3.86304835703
## [2,] -0.9322184104  0.04298865921
## 
## $weights[[1]][[2]]
##                [,1]
##  [1,]  0.8956443004
##  [2,]  1.4701831723
##  [3,] -0.8092935555
##  [4,]  1.3702232315
##  [5,] -0.6444118140
##  [6,] -1.1134640780
##  [7,]  2.3814555367
##  [8,]  1.8475723574
##  [9,] -1.5022154962
## [10,] -2.7636004492
## [11,]  3.6786709768
## 
## 
## 
## $startweights
## $startweights[[1]]
## $startweights[[1]][[1]]
##              [,1]         [,2]          [,3]          [,4]         [,5]
## [1,] 0.9810961943  1.158005273 0.03307021291  0.1845797332 -0.287970672
## [2,] 1.0439700952 -1.153805322 0.77682600953 -1.9242133103  0.167745174
##               [,6]         [,7]         [,8]          [,9]        [,10]
## [1,] -1.2144942321 0.8913244063 1.3149407424 -0.4805457751 -1.645364002
## [2,] -0.4158482435 0.9598983184 0.4575537614 -1.4139452335  0.712971785
## 
## $startweights[[1]][[2]]
##                 [,1]
##  [1,] -0.01911091991
##  [2,]  0.55542796919
##  [3,]  0.02564783216
##  [4,] -0.16598321533
##  [5,] -0.33489898123
##  [6,] -1.18342633817
##  [7,]  0.51364415831
##  [8,]  0.76332772301
##  [9,] -1.91077579032
## [10,]  0.78347801746
## [11,]  0.61018613228
## 
## 
## 
## $generalized.weights
## $generalized.weights[[1]]
##                [,1]
## 1  -0.0009297525235
## 2  -0.0006787391981
## 3  -0.1317960133543
## 4  -0.0007407207884
## 5  -0.0026506874752
## 6  -0.0005811059163
## 7  -0.1563373071040
## 8  -0.0009800729665
## 9  -0.0009480961330
## 10 -0.0010624854364
## 11 -0.0009329464720
## 12 -0.0011151314648
## 13 -0.0005322097193
## 14 -0.0010862467848
## 15 -0.0124768730375
## 16 -0.0168469982384
## 17 -0.0042145506680
## 18 -0.0048322914754
## 19 -0.0011407229334
## 20 -0.0015787936200
## 21 -0.0025719977400
## 22 -0.0009468913254
## 23 -0.0017526523027
## 24 -0.0010477940952
## 25 -0.0507961523724
## 26 -0.0007422670958
## 27 -2.7015001800179
## 28 -0.0165206329956
## 29 -0.0019275261767
## 30 -0.0061420906843
## 31 -0.0005547654705
## 32 -0.6246745655482
## 33 -0.0076255838562
## 34 -0.0027865913814
## 35 -0.0013810391264
## 36 -0.0025946053971
## 37 -0.0030297542068
## 38 -0.0011272465837
## 39 -0.0054565644466
## 40 -0.0006075898395
## 41 -0.0102786328651
## 42 -0.0007539933637
## 43 -0.0008851864781
## 44 -0.0011914549000
## 45 -0.0074170959432
## 46 -0.0008765107619
## 47 -0.0013666010628
## 48 -0.0041750229418
## 49 -0.0036517603759
## 50 -0.0008233013457
## 
## 
## $result.matrix
##                                         1
## error                     0.0001295426163
## reached.threshold         0.0093015274596
## steps                  2053.0000000000000
## Intercept.to.1layhid1     0.2019765555914
## Input.to.1layhid1         0.2875546643469
## Intercept.to.1layhid2     1.8315334821497
## Input.to.1layhid2        -0.1670601835712
## Intercept.to.1layhid3    -0.7615150276941
## Input.to.1layhid3         0.0485214213770
## Intercept.to.1layhid4     0.9377987225726
## Input.to.1layhid4        -0.3309593486213
## Intercept.to.1layhid5    -0.4140570074179
## Input.to.1layhid5        -0.0490272087897
## Intercept.to.1layhid6    -1.1707487685920
## Input.to.1layhid6         0.0410348519386
## Intercept.to.1layhid7    -0.0206529491797
## Input.to.1layhid7         0.0376126205935
## Intercept.to.1layhid8     0.8422610050336
## Input.to.1layhid8        -0.0513030863615
## Intercept.to.1layhid9    -1.2146627116325
## Input.to.1layhid9        -0.9322184103684
## Intercept.to.1layhid10   -3.8630483570336
## Input.to.1layhid10        0.0429886592140
## Intercept.to.Output       0.8956443003590
## 1layhid.1.to.Output       1.4701831722518
## 1layhid.2.to.Output      -0.8092935554897
## 1layhid.3.to.Output       1.3702232315283
## 1layhid.4.to.Output      -0.6444118140214
## 1layhid.5.to.Output      -1.1134640780220
## 1layhid.6.to.Output       2.3814555367198
## 1layhid.7.to.Output       1.8475723574344
## 1layhid.8.to.Output      -1.5022154962403
## 1layhid.9.to.Output      -2.7636004491744
## 1layhid.10.to.Output      3.6786709768344
## 
## attr(,"class")
## [1] "nn"
```

```r
#Plot the neural network
plot(net.sqrt)
 
#Test the neural network on some training data
testdata <- as.data.frame((1:10)^2) #Generate some squared numbers
net.results <- compute(net.sqrt, testdata) #Run them through the neural network
 
#See what properties net.sqrt has
ls(net.results)
```

```
## [1] "net.result" "neurons"
```

```r
#see the results
print(net.results$net.result)
```

```
##               [,1]
##  [1,] 0.9996470495
##  [2,] 1.9985378125
##  [3,] 3.0036859587
##  [4,] 3.9985490172
##  [5,] 5.0004146995
##  [6,] 6.0000254813
##  [7,] 7.0023937949
##  [8,] 7.9982178928
##  [9,] 9.0032042102
## [10,] 9.9874159003
```

```r
#Display a better version of the results
cleanoutput <- cbind(testdata,sqrt(testdata),
                         as.data.frame(net.results$net.result))
colnames(cleanoutput) <- c("Input","Expected Output","Neural Net Output")
print(cleanoutput)
```

```
##    Input Expected Output Neural Net Output
## 1      1               1      0.9996470495
## 2      4               2      1.9985378125
## 3      9               3      3.0036859587
## 4     16               4      3.9985490172
## 5     25               5      5.0004146995
## 6     36               6      6.0000254813
## 7     49               7      7.0023937949
## 8     64               8      7.9982178928
## 9     81               9      9.0032042102
## 10   100              10      9.9874159003
```

*Acknowledgement: this example excercise was from* http://gekkoquant.com/2012/05/26/neural-networks-with-r-simple-example/ 

