# Solutions ch. 10 - Artificial neural networks {#solutions-ann}

Solutions to exercises of chapter \@ref(ann).

## Exercise 1


```r
library("neuralnet")
 
#To create a neural network to perform square root

#Generate 50 random numbers uniformly distributed between 0 and 100
#And store them as a dataframe
traininginput <-  as.data.frame(runif(50, min=0, max=100))
trainingoutput <- sqrt(traininginput)
 
#Column bind the data into one variable
trainingdata <- cbind(traininginput,trainingoutput)
colnames(trainingdata) <- c("Input","Output")
 
#Train the neural network
#Will have 10 hidden layers
#Threshold is a numeric value specifying the threshold for the partial
#derivatives of the error function as stopping criteria.
net.sqrt <- neuralnet(Output~Input,trainingdata, hidden=10, threshold=0.01)
print(net.sqrt)
```

```
## $call
## neuralnet(formula = Output ~ Input, data = trainingdata, hidden = 10, 
##     threshold = 0.01)
## 
## $response
##         Output
## 1  4.125930470
## 2  8.782661448
## 3  1.495483619
## 4  5.799814292
## 5  5.453369722
## 6  4.309170433
## 7  9.948372246
## 8  9.393577229
## 9  9.150952435
## 10 7.337279089
## 11 6.414164983
## 12 5.658065863
## 13 4.894154620
## 14 8.653225694
## 15 9.155435581
## 16 7.244460706
## 17 8.597047730
## 18 7.753187352
## 19 4.751647197
## 20 9.958241961
## 21 9.780170216
## 22 2.809728405
## 23 8.862456592
## 24 9.363559624
## 25 9.640849449
## 26 9.760800377
## 27 8.700339744
## 28 9.150493100
## 29 2.885456668
## 30 3.515695591
## 31 1.175327451
## 32 7.195237319
## 33 6.983240511
## 34 4.572309942
## 35 7.578592120
## 36 7.542248961
## 37 6.394822254
## 38 3.613186522
## 39 7.656220538
## 40 5.045261631
## 41 8.804258436
## 42 9.710869982
## 43 4.890507247
## 44 8.641603054
## 45 9.024011819
## 46 9.076035407
## 47 9.701481500
## 48 3.679343938
## 49 7.781760940
## 50 8.125001688
## 
## $covariate
##               [,1]
##  [1,] 17.023302242
##  [2,] 77.135142102
##  [3,]  2.236471255
##  [4,] 33.637845819
##  [5,] 29.739241325
##  [6,] 18.568949820
##  [7,] 98.970110342
##  [8,] 88.239293150
##  [9,] 83.739930461
## [10,] 53.835664433
## [11,] 41.141512431
## [12,] 32.013709308
## [13,] 23.952749441
## [14,] 74.878314906
## [15,] 83.822000679
## [16,] 52.482210915
## [17,] 73.909229669
## [18,] 60.111914109
## [19,] 22.578151082
## [20,] 99.166582944
## [21,] 95.651729451
## [22,]  7.894573710
## [23,] 78.543136851
## [24,] 87.676248839
## [25,] 92.945978092
## [26,] 95.273224008
## [27,] 75.695911655
## [28,] 83.731523971
## [29,]  8.325860184
## [30,] 12.360115489
## [31,]  1.381394616
## [32,] 51.771440078
## [33,] 48.765648040
## [34,] 20.906018210
## [35,] 57.435058523
## [36,] 56.885519391
## [37,] 40.893751662
## [38,] 13.055116846
## [39,] 58.617712930
## [40,] 25.454664929
## [41,] 77.514966601
## [42,] 94.300995814
## [43,] 23.917061137
## [44,] 74.677303340
## [45,] 81.432789308
## [46,] 82.374418713
## [47,] 94.118743297
## [48,] 13.537571812
## [49,] 60.555803333
## [50,] 66.015652427
## 
## $model.list
## $model.list$response
## [1] "Output"
## 
## $model.list$variables
## [1] "Input"
## 
## 
## $err.fct
## function (x, y) 
## {
##     1/2 * (y - x)^2
## }
## <environment: 0x39ad9d0>
## attr(,"type")
## [1] "sse"
## 
## $act.fct
## function (x) 
## {
##     1/(1 + exp(-x))
## }
## <environment: 0x39ad9d0>
## attr(,"type")
## [1] "logistic"
## 
## $linear.output
## [1] TRUE
## 
## $data
##           Input      Output
## 1  17.023302242 4.125930470
## 2  77.135142102 8.782661448
## 3   2.236471255 1.495483619
## 4  33.637845819 5.799814292
## 5  29.739241325 5.453369722
## 6  18.568949820 4.309170433
## 7  98.970110342 9.948372246
## 8  88.239293150 9.393577229
## 9  83.739930461 9.150952435
## 10 53.835664433 7.337279089
## 11 41.141512431 6.414164983
## 12 32.013709308 5.658065863
## 13 23.952749441 4.894154620
## 14 74.878314906 8.653225694
## 15 83.822000679 9.155435581
## 16 52.482210915 7.244460706
## 17 73.909229669 8.597047730
## 18 60.111914109 7.753187352
## 19 22.578151082 4.751647197
## 20 99.166582944 9.958241961
## 21 95.651729451 9.780170216
## 22  7.894573710 2.809728405
## 23 78.543136851 8.862456592
## 24 87.676248839 9.363559624
## 25 92.945978092 9.640849449
## 26 95.273224008 9.760800377
## 27 75.695911655 8.700339744
## 28 83.731523971 9.150493100
## 29  8.325860184 2.885456668
## 30 12.360115489 3.515695591
## 31  1.381394616 1.175327451
## 32 51.771440078 7.195237319
## 33 48.765648040 6.983240511
## 34 20.906018210 4.572309942
## 35 57.435058523 7.578592120
## 36 56.885519391 7.542248961
## 37 40.893751662 6.394822254
## 38 13.055116846 3.613186522
## 39 58.617712930 7.656220538
## 40 25.454664929 5.045261631
## 41 77.514966601 8.804258436
## 42 94.300995814 9.710869982
## 43 23.917061137 4.890507247
## 44 74.677303340 8.641603054
## 45 81.432789308 9.024011819
## 46 82.374418713 9.076035407
## 47 94.118743297 9.701481500
## 48 13.537571812 3.679343938
## 49 60.555803333 7.781760940
## 50 66.015652427 8.125001688
## 
## $net.result
## $net.result[[1]]
##           [,1]
## 1  4.126729142
## 2  8.782367440
## 3  1.491496242
## 4  5.797538512
## 5  5.451994589
## 6  4.311194047
## 7  9.944613137
## 8  9.395585718
## 9  9.152268758
## 10 7.337826056
## 11 6.412935221
## 12 5.656010539
## 13 4.895807564
## 14 8.652512996
## 15 9.156770755
## 16 7.245044434
## 17 8.596196445
## 18 7.753032490
## 19 4.753901642
## 20 9.954209920
## 21 9.779917365
## 22 2.814376163
## 23 8.862479543
## 24 9.365533519
## 25 9.642145282
## 26 9.760827599
## 27 8.699764115
## 28 9.151807485
## 29 2.888143164
## 30 3.511336641
## 31 1.178034294
## 32 7.195817796
## 33 6.983622630
## 34 4.574918947
## 35 7.578814001
## 36 7.542537632
## 37 6.393529225
## 38 3.609302209
## 39 7.656284254
## 40 5.046094072
## 41 8.804046355
## 42 9.711518064
## 43 4.892178168
## 44 8.640859425
## 45 9.024758937
## 46 9.077021550
## 47 9.702230904
## 48 3.675933177
## 49 7.781539121
## 50 8.124055801
## 
## 
## $weights
## $weights[[1]]
## $weights[[1]][[1]]
##                [,1]          [,2]         [,3]           [,4]
## [1,] -1.64126975804 -0.9746625006 0.2702837427 -3.29392677009
## [2,]  0.03001549611  0.1676391879 0.0289333260  0.03433666232
##               [,5]           [,6]        [,7]           [,8]          [,9]
## [1,] 1.33543946447  1.01867626785 15.46642834  0.01991664415 1.49954821747
## [2,] 0.02980260687 -0.04600076456 15.49574642 -0.04337085763 0.02881932542
##              [,10]
## [1,] -0.7334715026
## [2,] -0.4499189875
## 
## $weights[[1]][[2]]
##                [,1]
##  [1,]  1.5804716863
##  [2,]  1.3767742659
##  [3,]  1.3242134600
##  [4,]  1.2524400670
##  [5,]  4.0440872120
##  [6,]  1.9340366431
##  [7,] -1.6125615521
##  [8,] -0.4991173433
##  [9,] -4.5563079491
## [10,]  1.3404279364
## [11,] -3.3469105400
## 
## 
## 
## $startweights
## $startweights[[1]]
## $startweights[[1]][[1]]
##               [,1]          [,2]           [,3]          [,4]         [,5]
## [1,] 0.01969758637 -0.9772266789  0.58033296706 -2.7644194629 1.6674311858
## [2,] 0.96052865427  1.7617471893 -0.02179931265 -0.4847708329 0.1269417026
##              [,6]          [,7]          [,8]         [,9]         [,10]
## [1,] 1.0203286174 -0.6744912917 -0.5738993347  1.431539985  0.2942990287
## [2,] 0.5772191892  0.9860549457  0.2895337241 -0.517535145 -1.7099059288
## 
## $startweights[[1]][[2]]
##                 [,1]
##  [1,]  0.31896922475
##  [2,] -0.22492324121
##  [3,]  0.06691481811
##  [4,] -0.23907264018
##  [5,]  0.32207458383
##  [6,]  0.67534796918
##  [7,] -1.19857143157
##  [8,] -1.76061980485
##  [9,] -3.21317383562
## [10,]  0.08173926858
## [11,] -0.02077445956
## 
## 
## 
## $generalized.weights
## $generalized.weights[[1]]
##                [,1]
## 1  -0.0094694514438
## 2  -0.0008360525882
## 3  -0.4652583902183
## 4  -0.0030969919691
## 5  -0.0037612450088
## 6  -0.0081683660712
## 7  -0.0005496348406
## 8  -0.0006753385215
## 9  -0.0007354021933
## 10 -0.0014642935877
## 11 -0.0022530221980
## 12 -0.0033479450720
## 13 -0.0053298868218
## 14 -0.0008750270651
## 15 -0.0007342540468
## 16 -0.0015252650278
## 17 -0.0008926493997
## 18 -0.0012288699753
## 19 -0.0058765949766
## 20 -0.0005475056912
## 21 -0.0005864236245
## 22 -0.0339210627649
## 23 -0.0008130574959
## 24 -0.0006825598285
## 25 -0.0006176870455
## 26 -0.0005907246460
## 27 -0.0008605868980
## 28 -0.0007355199201
## 29 -0.0309818433672
## 30 -0.0161805250874
## 31 -1.8726040467196
## 32 -0.0015589992703
## 33 -0.0017162197837
## 34 -0.0066834448986
## 35 -0.0013206972042
## 36 -0.0013410293886
## 37 -0.0022747748381
## 38 -0.0147868196178
## 39 -0.0012787030820
## 40 -0.0048259305831
## 41 -0.0008297552669
## 42 -0.0006018777035
## 43 -0.0053429613664
## 44 -0.0008786361678
## 45 -0.0007686081634
## 46 -0.0007548315839
## 47 -0.0006039857692
## 48 -0.0139244506490
## 49 -0.0012147164105
## 50 -0.0010616570141
## 
## 
## $result.matrix
##                                          1
## error                     0.00009368946125
## reached.threshold         0.00993315276334
## steps                  8157.00000000000000
## Intercept.to.1layhid1    -1.64126975803839
## Input.to.1layhid1         0.03001549611278
## Intercept.to.1layhid2    -0.97466250058488
## Input.to.1layhid2         0.16763918787286
## Intercept.to.1layhid3     0.27028374265626
## Input.to.1layhid3         0.02893332599619
## Intercept.to.1layhid4    -3.29392677008691
## Input.to.1layhid4         0.03433666231552
## Intercept.to.1layhid5     1.33543946446699
## Input.to.1layhid5         0.02980260687196
## Intercept.to.1layhid6     1.01867626784836
## Input.to.1layhid6        -0.04600076456439
## Intercept.to.1layhid7    15.46642833661319
## Input.to.1layhid7        15.49574642303145
## Intercept.to.1layhid8     0.01991664415045
## Input.to.1layhid8        -0.04337085762595
## Intercept.to.1layhid9     1.49954821747155
## Input.to.1layhid9         0.02881932542432
## Intercept.to.1layhid10   -0.73347150258388
## Input.to.1layhid10       -0.44991898752053
## Intercept.to.Output       1.58047168629361
## 1layhid.1.to.Output       1.37677426590700
## 1layhid.2.to.Output       1.32421345999691
## 1layhid.3.to.Output       1.25244006699152
## 1layhid.4.to.Output       4.04408721195711
## 1layhid.5.to.Output       1.93403664311618
## 1layhid.6.to.Output      -1.61256155210686
## 1layhid.7.to.Output      -0.49911734330743
## 1layhid.8.to.Output      -4.55630794907750
## 1layhid.9.to.Output       1.34042793643799
## 1layhid.10.to.Output     -3.34691053997365
## 
## attr(,"class")
## [1] "nn"
```

```r
#Plot the neural network
plot(net.sqrt)
 
#Test the neural network on some training data
testdata <- as.data.frame((1:10)^2) #Generate some squared numbers
net.results <- compute(net.sqrt, testdata) #Run them through the neural network
 
#See what properties net.sqrt has
ls(net.results)
```

```
## [1] "net.result" "neurons"
```

```r
#see the results
print(net.results$net.result)
```

```
##              [,1]
##  [1,] 1.023738672
##  [2,] 2.012798079
##  [3,] 3.000039429
##  [4,] 3.999657670
##  [5,] 5.001090402
##  [6,] 5.997759277
##  [7,] 7.000408465
##  [8,] 7.999280991
##  [9,] 9.000636172
## [10,] 9.994720383
```

```r
#Display a better version of the results
cleanoutput <- cbind(testdata,sqrt(testdata),
                         as.data.frame(net.results$net.result))
colnames(cleanoutput) <- c("Input","Expected Output","Neural Net Output")
print(cleanoutput)
```

```
##    Input Expected Output Neural Net Output
## 1      1               1       1.023738672
## 2      4               2       2.012798079
## 3      9               3       3.000039429
## 4     16               4       3.999657670
## 5     25               5       5.001090402
## 6     36               6       5.997759277
## 7     49               7       7.000408465
## 8     64               8       7.999280991
## 9     81               9       9.000636172
## 10   100              10       9.994720383
```

*Acknowledgement: this example excercise was from* http://gekkoquant.com/2012/05/26/neural-networks-with-r-simple-example/ 

