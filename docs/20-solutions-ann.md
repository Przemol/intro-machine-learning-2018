# Solutions ch. 10 - Artificial neural networks {#solutions-ann}

Solutions to exercises of chapter \@ref(ann).

## Exercise 1


```r
library("neuralnet")
 
#To create a neural network to perform square root

#Generate 50 random numbers uniformly distributed between 0 and 100
#And store them as a dataframe
traininginput <-  as.data.frame(runif(50, min=0, max=100))
trainingoutput <- sqrt(traininginput)
 
#Column bind the data into one variable
trainingdata <- cbind(traininginput,trainingoutput)
colnames(trainingdata) <- c("Input","Output")
 
#Train the neural network
#Will have 10 hidden layers
#Threshold is a numeric value specifying the threshold for the partial
#derivatives of the error function as stopping criteria.
net.sqrt <- neuralnet(Output~Input,trainingdata, hidden=10, threshold=0.01)
print(net.sqrt)
```

```
## $call
## neuralnet(formula = Output ~ Input, data = trainingdata, hidden = 10, 
##     threshold = 0.01)
## 
## $response
##         Output
## 1  9.657403448
## 2  7.644583245
## 3  9.398999897
## 4  5.986777179
## 5  6.975494017
## 6  7.644305578
## 7  9.097398680
## 8  6.588953309
## 9  7.123291875
## 10 9.142742664
## 11 9.037765476
## 12 6.117704860
## 13 8.045171785
## 14 3.307092955
## 15 7.750307850
## 16 6.223870009
## 17 3.533152607
## 18 9.273617760
## 19 7.308702972
## 20 3.253209227
## 21 7.089696405
## 22 9.864283582
## 23 8.869294196
## 24 8.852521432
## 25 5.435231611
## 26 3.394345411
## 27 7.053877461
## 28 2.478257840
## 29 3.100089916
## 30 3.554738655
## 31 7.031022300
## 32 5.330022577
## 33 8.704544343
## 34 7.316298699
## 35 3.421867871
## 36 8.918499253
## 37 2.989272731
## 38 5.581031524
## 39 6.223000938
## 40 4.321728161
## 41 7.321257449
## 42 9.338900886
## 43 2.134129641
## 44 6.514278883
## 45 4.823920826
## 46 9.729693279
## 47 3.917731271
## 48 6.927733579
## 49 8.780863555
## 50 8.960442886
## 
## $covariate
##               [,1]
##  [1,] 93.265441363
##  [2,] 58.439652994
##  [3,] 88.341199071
##  [4,] 35.841500992
##  [5,] 48.657516786
##  [6,] 58.435407770
##  [7,] 82.762662740
##  [8,] 43.414305709
##  [9,] 50.741287135
## [10,] 83.589743427
## [11,] 81.681204797
## [12,] 37.426312757
## [13,] 64.724789048
## [14,] 10.936863814
## [15,] 60.067271767
## [16,] 38.736557891
## [17,] 12.483167346
## [18,] 85.999986366
## [19,] 53.417139128
## [20,] 10.583370272
## [21,] 50.263795117
## [22,] 97.304090578
## [23,] 78.664379544
## [24,] 78.367135697
## [25,] 29.541742662
## [26,] 11.521580769
## [27,] 49.757187231
## [28,]  6.141761923
## [29,]  9.610557486
## [30,] 12.636166904
## [31,] 49.435274582
## [32,] 28.409140673
## [33,] 75.769092212
## [34,] 53.528226656
## [35,] 11.709179729
## [36,] 79.539628932
## [37,]  8.935751463
## [38,] 31.147912866
## [39,] 38.725740672
## [40,] 18.677334301
## [41,] 53.600810631
## [42,] 87.215069751
## [43,]  4.554509325
## [44,] 42.435829365
## [45,] 23.270212137
## [46,] 94.666931313
## [47,] 15.348618315
## [48,] 47.993492545
## [49,] 77.103564772
## [50,] 80.289536715
## 
## $model.list
## $model.list$response
## [1] "Output"
## 
## $model.list$variables
## [1] "Input"
## 
## 
## $err.fct
## function (x, y) 
## {
##     1/2 * (y - x)^2
## }
## <environment: 0x40db880>
## attr(,"type")
## [1] "sse"
## 
## $act.fct
## function (x) 
## {
##     1/(1 + exp(-x))
## }
## <environment: 0x40db880>
## attr(,"type")
## [1] "logistic"
## 
## $linear.output
## [1] TRUE
## 
## $data
##           Input      Output
## 1  93.265441363 9.657403448
## 2  58.439652994 7.644583245
## 3  88.341199071 9.398999897
## 4  35.841500992 5.986777179
## 5  48.657516786 6.975494017
## 6  58.435407770 7.644305578
## 7  82.762662740 9.097398680
## 8  43.414305709 6.588953309
## 9  50.741287135 7.123291875
## 10 83.589743427 9.142742664
## 11 81.681204797 9.037765476
## 12 37.426312757 6.117704860
## 13 64.724789048 8.045171785
## 14 10.936863814 3.307092955
## 15 60.067271767 7.750307850
## 16 38.736557891 6.223870009
## 17 12.483167346 3.533152607
## 18 85.999986366 9.273617760
## 19 53.417139128 7.308702972
## 20 10.583370272 3.253209227
## 21 50.263795117 7.089696405
## 22 97.304090578 9.864283582
## 23 78.664379544 8.869294196
## 24 78.367135697 8.852521432
## 25 29.541742662 5.435231611
## 26 11.521580769 3.394345411
## 27 49.757187231 7.053877461
## 28  6.141761923 2.478257840
## 29  9.610557486 3.100089916
## 30 12.636166904 3.554738655
## 31 49.435274582 7.031022300
## 32 28.409140673 5.330022577
## 33 75.769092212 8.704544343
## 34 53.528226656 7.316298699
## 35 11.709179729 3.421867871
## 36 79.539628932 8.918499253
## 37  8.935751463 2.989272731
## 38 31.147912866 5.581031524
## 39 38.725740672 6.223000938
## 40 18.677334301 4.321728161
## 41 53.600810631 7.321257449
## 42 87.215069751 9.338900886
## 43  4.554509325 2.134129641
## 44 42.435829365 6.514278883
## 45 23.270212137 4.823920826
## 46 94.666931313 9.729693279
## 47 15.348618315 3.917731271
## 48 47.993492545 6.927733579
## 49 77.103564772 8.780863555
## 50 80.289536715 8.960442886
## 
## $net.result
## $net.result[[1]]
##           [,1]
## 1  9.655555921
## 2  7.641856175
## 3  9.400959482
## 4  5.989632904
## 5  6.974693137
## 6  7.641578666
## 7  9.100065691
## 8  6.590009188
## 9  7.121850375
## 10 9.145470828
## 11 9.040289028
## 12 6.120411255
## 13 8.042894353
## 14 3.308062532
## 15 7.747567111
## 16 6.226335865
## 17 3.534486678
## 18 9.276227855
## 19 7.306600177
## 20 3.253761588
## 21 7.088393150
## 22 9.855888560
## 23 8.871128104
## 24 8.854270259
## 25 5.436582101
## 26 3.395724855
## 27 7.052726744
## 28 2.478779442
## 29 3.098948476
## 30 3.555994561
## 31 7.029971459
## 32 5.330708564
## 33 8.705472548
## 34 7.314173006
## 35 3.423305247
## 36 8.920568684
## 37 2.986768129
## 38 5.583122391
## 39 6.225469152
## 40 4.317279411
## 41 7.319117003
## 42 9.341248865
## 43 2.134093027
## 44 6.515675381
## 45 4.820818239
## 46 9.725981455
## 47 3.916031016
## 48 6.927154730
## 49 8.782227607
## 50 8.962693339
## 
## 
## $weights
## $weights[[1]]
## $weights[[1]][[1]]
##                [,1]          [,2]          [,3]          [,4]
## [1,] -0.45348715807 -2.1969869277  1.8981832733  0.4868760092
## [2,] -0.03834269059  0.8861386545 -0.3696121602 -0.5609156452
##                [,5]           [,6]          [,7]           [,8]
## [1,] -0.19591721588 -0.31810391061  4.6169420166 -0.40422216387
## [2,]  0.03786161674  0.04000276745 -0.0451892545  0.09484790988
##                [,9]         [,10]
## [1,] -1.73260271532 -1.4809392811
## [2,]  0.02946012977  0.0315574764
## 
## $weights[[1]][[2]]
##                [,1]
##  [1,] -0.5265241089
##  [2,] -1.7458196963
##  [3,]  1.4134975447
##  [4,] -0.8014974873
##  [5,]  1.9217794045
##  [6,]  1.4410861041
##  [7,]  2.5527243032
##  [8,] -1.6790542063
##  [9,]  2.2957278008
## [10,]  3.2625917142
## [11,]  1.5426534352
## 
## 
## 
## $startweights
## $startweights[[1]]
## $startweights[[1]][[1]]
##               [,1]        [,2]           [,3]          [,4]         [,5]
## [1,] -1.3109670179 1.555506342 -0.05770201011  0.3864377785 0.6780389613
## [2,]  0.2891175849 1.984037153 -0.75088371807 -1.1612054163 0.3438929532
##               [,6]         [,7]         [,8]          [,9]        [,10]
## [1,]  0.2696990770 1.0158846147 0.3920178903 -0.4745499186 0.7345652024
## [2,] -0.3614996136 0.4042550793 1.3684641988  1.3596644107 0.9259391859
## 
## $startweights[[1]][[2]]
##                 [,1]
##  [1,] -1.62888193650
##  [2,] -1.31962249218
##  [3,]  0.31114027238
##  [4,] -0.02704225501
##  [5,]  1.97661354307
##  [6,] -0.19087371367
##  [7,]  0.33538068355
##  [8,] -0.84798724075
##  [9,]  1.12384387117
## [10,]  0.57507885811
## [11,] -0.53944063263
## 
## 
## 
## $generalized.weights
## $generalized.weights[[1]]
##                [,1]
## 1  -0.0006052549954
## 2  -0.0012878961764
## 3  -0.0006683551407
## 4  -0.0027932364949
## 5  -0.0017122139017
## 6  -0.0012880406109
## 7  -0.0007469912837
## 8  -0.0020503185771
## 9  -0.0016034485829
## 10 -0.0007347439199
## 11 -0.0007633615023
## 12 -0.0026032639751
## 13 -0.0011002500521
## 14 -0.0199329492552
## 15 -0.0012344548693
## 16 -0.0024620550272
## 17 -0.0157468217976
## 18 -0.0007002804871
## 19 -0.0014801218575
## 20 -0.0211433649483
## 21 -0.0016273081916
## 22 -0.0005567363423
## 23 -0.0008113976223
## 24 -0.0008163374409
## 25 -0.0038362303858
## 26 -0.0181563286866
## 27 -0.0016532944811
## 28 -0.0538250025731
## 29 -0.0251064708815
## 30 -0.0154131626318
## 31 -0.0016701785318
## 32 -0.0040909437486
## 33 -0.0008612965401
## 34 -0.0014753533162
## 35 -0.0176399204718
## 36 -0.0007970771558
## 37 -0.0285096743713
## 38 -0.0035161807512
## 39 -0.0024631674325
## 40 -0.0080571935381
## 41 -0.0014722516763
## 42 -0.0006835353706
## 43 -0.1012548832788
## 44 -0.0021262502480
## 45 -0.0056650122577
## 46 -0.0005881284819
## 47 -0.0110677527124
## 48 -0.0017495594032
## 49 -0.0008377911079
## 50 -0.0007850644042
## 
## 
## $result.matrix
##                                         1
## error                     0.0001388173224
## reached.threshold         0.0098673193500
## steps                  5840.0000000000000
## Intercept.to.1layhid1    -0.4534871580750
## Input.to.1layhid1        -0.0383426905887
## Intercept.to.1layhid2    -2.1969869276718
## Input.to.1layhid2         0.8861386544990
## Intercept.to.1layhid3     1.8981832733161
## Input.to.1layhid3        -0.3696121602342
## Intercept.to.1layhid4     0.4868760092229
## Input.to.1layhid4        -0.5609156452044
## Intercept.to.1layhid5    -0.1959172158826
## Input.to.1layhid5         0.0378616167377
## Intercept.to.1layhid6    -0.3181039106146
## Input.to.1layhid6         0.0400027674466
## Intercept.to.1layhid7     4.6169420165797
## Input.to.1layhid7        -0.0451892545009
## Intercept.to.1layhid8    -0.4042221638745
## Input.to.1layhid8         0.0948479098755
## Intercept.to.1layhid9    -1.7326027153194
## Input.to.1layhid9         0.0294601297728
## Intercept.to.1layhid10   -1.4809392811024
## Input.to.1layhid10        0.0315574763998
## Intercept.to.Output      -0.5265241088532
## 1layhid.1.to.Output      -1.7458196962661
## 1layhid.2.to.Output       1.4134975447445
## 1layhid.3.to.Output      -0.8014974873389
## 1layhid.4.to.Output       1.9217794044871
## 1layhid.5.to.Output       1.4410861041232
## 1layhid.6.to.Output       2.5527243031610
## 1layhid.7.to.Output      -1.6790542063111
## 1layhid.8.to.Output       2.2957278007758
## 1layhid.9.to.Output       3.2625917142180
## 1layhid.10.to.Output      1.5426534352353
## 
## attr(,"class")
## [1] "nn"
```

```r
#Plot the neural network
plot(net.sqrt)
 
#Test the neural network on some training data
testdata <- as.data.frame((1:10)^2) #Generate some squared numbers
net.results <- compute(net.sqrt, testdata) #Run them through the neural network
 
#See what properties net.sqrt has
ls(net.results)
```

```
## [1] "net.result" "neurons"
```

```r
#see the results
print(net.results$net.result)
```

```
##              [,1]
##  [1,] 1.247262978
##  [2,] 1.990933454
##  [3,] 2.997619561
##  [4,] 3.997525334
##  [5,] 4.998192786
##  [6,] 6.002848683
##  [7,] 6.999087610
##  [8,] 7.997603878
##  [9,] 9.002401063
## [10,] 9.984977687
```

```r
#Display a better version of the results
cleanoutput <- cbind(testdata,sqrt(testdata),
                         as.data.frame(net.results$net.result))
colnames(cleanoutput) <- c("Input","Expected Output","Neural Net Output")
print(cleanoutput)
```

```
##    Input Expected Output Neural Net Output
## 1      1               1       1.247262978
## 2      4               2       1.990933454
## 3      9               3       2.997619561
## 4     16               4       3.997525334
## 5     25               5       4.998192786
## 6     36               6       6.002848683
## 7     49               7       6.999087610
## 8     64               8       7.997603878
## 9     81               9       9.002401063
## 10   100              10       9.984977687
```

*Acknowledgement: this example excercise was from* http://gekkoquant.com/2012/05/26/neural-networks-with-r-simple-example/ 

